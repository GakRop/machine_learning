# -*- coding: utf-8 -*-
"""Project 1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lXiMg1jAQs_E7A1cgWGN7l8O9fSfK-ve
"""

# Project 1
#Overall for each part (coding, writing, and video segements) were equally distributed between the two of us Steven Ohms and Gak Roppongi
#A majority of the time we were working together in person, and constantly looked over/edited each others code
#Note whenever a cell says one of our names, we assume a majority of the work in the cell was done by that individual, but was still split between the two of us

import numpy as np
import pandas as pd
import math
import random

#Gak Roppongi
#importing the data sets, and deaal with the missing values and one-hot encoding
#this website below was referred to to import the data sets from UCI
#https://towardsdatascience.com/how-to-use-data-files-from-uci-68b740b4719d

breast_cancer_dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', 
                                    names = ["radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave points", 
                                             "symmetry", "fractal dimension", "class"])
#"symmetry" may be label-encoded, but I'm not sure 
#the sum of number of instances of 1 ... 7 in "class" attribute is 699 = number of all instances
#therefore, "class" should be the categorical attribute
#no categorical value is missed
#There are 16 instances in Groups 1 to 6 that contain a single missing (i.e., unavailable) attribute value, now denoted by "?".  
#699 * 11

glass_dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data', 
                            names = ["id", "RI", "Na", "Mg", "Al", "Si", "K", "Ca", "Ba",  "Fe", "type of glass"])
#the "type of glass" is label-encoded
#everything else is numerical attribute
#Number of Attributes: 10 (including an Id#) plus the class attribute -- all attributes are continuously valued
#the last attribute, "class", has label-encoded for 7 categories from 1~7
#no missing attributes values
#214 * 11 

iris_dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', 
                           names = ["sepal length", "sepal width", "petal length", "petal width", "class"])
#"class" instances are string data type
#attributes 1~4 are numerical
#attribute 5 is categorical
#no missing attribute values
#149 * 5

soybean_dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/soybean/soybean-small.data', 
                              names = ["date", "plant-stand", "precip", "temp", "hail", "crop-hist", "area-damaged", 
                                       "severity", "seed-tmt", "germination", "plant-growth", "leaves", "leafspots-halo", 
                                       "leafspots-marg", "leadspot-size", "leaf-shread", "lead-malf", "lead-mild", "stem", 
                                       "lodging", "stem-cankers", "fruiting-bodies", "external-decay", "mycelium", "int-discolor", 
                                       "sclerotia", "fruit-pods", "fruit-spots", "seed", "mold-growth", "seed-discolor", "seed-size", "shriveling", "roots"])
#many of the attributes are string data type and label-encoded
#no missing attribute values
#all values have been normalized
#"roots" is the categorical value
#46 * 36

vote_dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data', 
                           names = ["class name", "handicapped-infants", "water-project-cost-sharing", "adoption-of-the-budget-resolution", 
                                    "physician-fee-freeze", "el-salvador-aid", "religious-groups-in-schools", "anti-satellite-test-ban", 
                                    "aid-to-nicaraguan-contras", "mx-missile", "immigration", "synfuels-corporation-cutback", 
                                    "education-spending", "superfund-right-to-sue", "crime", "duty-free-exports", "export-administration-act-south-africa"])
#most attributes are yes or no, and others are string. Any instance with missing value should be deleted or treated with forward/backward filling.
#the first attribute shows whether the instance is by a republicant or a democrat
#all other attributes are either yes or no
#therefore, all attributes have to be one-hot-encoded
#missing attributes are denoted by "?"
#434 * 17

breast_class = np.array([2, 4])
glass_class = np.array([1, 2, 3, 5, 6, 7])
iris_class = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])
soybean_class = np.array(['D1', 'D2', 'D3', 'D4'])
vote_class = np.array(["republican", "democrat"])

#Gak Roppongi
soybean_dataset = soybean_dataset.reset_index(drop = True)

#Steven Ohms
breast_cancer_dataset.sort_values(by=["class"], inplace=True)
glass_dataset.sort_values(by=["type of glass"], inplace=True)
iris_dataset.sort_values(by=["class"], inplace=True)
soybean_dataset.sort_values(by=["roots"], inplace=True)
vote_dataset.sort_values(by=["class name"], inplace=True)

#Gak Roppongi
#we will replace all the "?" value with np.nan value so that we can handle it easier

breast_cancer_dataset = breast_cancer_dataset.replace(["?"], np.nan)
glass_dataset = glass_dataset.replace(["?"], np.nan)
iris_dataset = iris_dataset.replace(["?"], np.nan)
soybean_dataset = soybean_dataset.replace(["?"], np.nan)

vote_dataset["handicapped-infants"] = vote_dataset["handicapped-infants"].replace(["n"], ["handicapped-n"])
vote_dataset["handicapped-infants"] = vote_dataset["handicapped-infants"].replace(["y"], ["handicapped-y"])
vote_dataset["handicapped-infants"] = vote_dataset["handicapped-infants"].replace(["?"], ["handicapped-absent"])
vote_dataset["water-project-cost-sharing"] = vote_dataset["water-project-cost-sharing"].replace(["n"], ["water-n"])
vote_dataset["water-project-cost-sharing"] = vote_dataset["water-project-cost-sharing"].replace(["y"], ["water-y"])
vote_dataset["water-project-cost-sharing"] = vote_dataset["water-project-cost-sharing"].replace(["?"], ["water-absent"])
vote_dataset["adoption-of-the-budget-resolution"] = vote_dataset["adoption-of-the-budget-resolution"].replace(["n"], ["adoption-n"])
vote_dataset["adoption-of-the-budget-resolution"] = vote_dataset["adoption-of-the-budget-resolution"].replace(["y"], ["adoption-y"])
vote_dataset["adoption-of-the-budget-resolution"] = vote_dataset["adoption-of-the-budget-resolution"].replace(["?"], ["adoption-absent"])
vote_dataset["physician-fee-freeze"] = vote_dataset["physician-fee-freeze"].replace(["n"], ["physician-n"])
vote_dataset["physician-fee-freeze"] = vote_dataset["physician-fee-freeze"].replace(["y"], ["physician-y"])
vote_dataset["physician-fee-freeze"] = vote_dataset["physician-fee-freeze"].replace(["?"], ["physician-absent"])
vote_dataset["el-salvador-aid"] = vote_dataset["el-salvador-aid"].replace(["n"], ["el-n"])
vote_dataset["el-salvador-aid"] = vote_dataset["el-salvador-aid"].replace(["y"], ["el-y"])
vote_dataset["el-salvador-aid"] = vote_dataset["el-salvador-aid"].replace(["?"], ["el-absent"])
vote_dataset["religious-groups-in-schools"] = vote_dataset["religious-groups-in-schools"].replace(["n"], ["religious-n"])
vote_dataset["religious-groups-in-schools"] = vote_dataset["religious-groups-in-schools"].replace(["y"], ["religious-y"])
vote_dataset["religious-groups-in-schools"] = vote_dataset["religious-groups-in-schools"].replace(["?"], ["religious-absent"])
vote_dataset["anti-satellite-test-ban"] = vote_dataset["anti-satellite-test-ban"].replace(["n"], ["anti-n"])
vote_dataset["anti-satellite-test-ban"] = vote_dataset["anti-satellite-test-ban"].replace(["y"], ["anti-y"])
vote_dataset["anti-satellite-test-ban"] = vote_dataset["anti-satellite-test-ban"].replace(["?"], ["anti-absent"])
vote_dataset["aid-to-nicaraguan-contras"] = vote_dataset["aid-to-nicaraguan-contras"].replace(["n"], ["aid-n"])
vote_dataset["aid-to-nicaraguan-contras"] = vote_dataset["aid-to-nicaraguan-contras"].replace(["y"], ["aid-y"])
vote_dataset["aid-to-nicaraguan-contras"] = vote_dataset["aid-to-nicaraguan-contras"].replace(["?"], ["aid-absent"])
vote_dataset["mx-missile"] = vote_dataset["mx-missile"].replace(["n"], ["mx-n"])
vote_dataset["mx-missile"] = vote_dataset["mx-missile"].replace(["y"], ["mx-y"])
vote_dataset["mx-missile"] = vote_dataset["mx-missile"].replace(["?"], ["mx-absent"])
vote_dataset["immigration"] = vote_dataset["immigration"].replace(["n"], ["immigration-n"])
vote_dataset["immigration"] = vote_dataset["immigration"].replace(["y"], ["immigration-y"])
vote_dataset["immigration"] = vote_dataset["immigration"].replace(["?"], ["immigration-absent"])
vote_dataset["synfuels-corporation-cutback"] = vote_dataset["synfuels-corporation-cutback"].replace(["n"], ["synfuels-n"])
vote_dataset["synfuels-corporation-cutback"] = vote_dataset["synfuels-corporation-cutback"].replace(["y"], ["synfuels-y"])
vote_dataset["synfuels-corporation-cutback"] = vote_dataset["synfuels-corporation-cutback"].replace(["?"], ["synfuels-absent"])
vote_dataset["education-spending"] = vote_dataset["education-spending"].replace(["n"], ["education-n"])
vote_dataset["education-spending"] = vote_dataset["education-spending"].replace(["y"], ["education-y"])
vote_dataset["education-spending"] = vote_dataset["education-spending"].replace(["?"], ["education-absent"])
vote_dataset["superfund-right-to-sue"] = vote_dataset["superfund-right-to-sue"].replace(["n"], ["superfund-n"])
vote_dataset["superfund-right-to-sue"] = vote_dataset["superfund-right-to-sue"].replace(["y"], ["superfund-y"])
vote_dataset["superfund-right-to-sue"] = vote_dataset["superfund-right-to-sue"].replace(["?"], ["superfund-absent"])
vote_dataset["crime"] = vote_dataset["crime"].replace(["n"], ["crime-n"])
vote_dataset["crime"] = vote_dataset["crime"].replace(["y"], ["crime-y"])
vote_dataset["crime"] = vote_dataset["crime"].replace(["?"], ["crime-absent"])
vote_dataset["duty-free-exports"] = vote_dataset["duty-free-exports"].replace(["n"], ["duty-n"])
vote_dataset["duty-free-exports"] = vote_dataset["duty-free-exports"].replace(["y"], ["duty-y"])
vote_dataset["duty-free-exports"] = vote_dataset["duty-free-exports"].replace(["?"], ["duty-absent"])
vote_dataset["export-administration-act-south-africa"] = vote_dataset["export-administration-act-south-africa"].replace(["n"], ["export-n"])
vote_dataset["export-administration-act-south-africa"] = vote_dataset["export-administration-act-south-africa"].replace(["y"], ["export-y"])
vote_dataset["export-administration-act-south-africa"] = vote_dataset["export-administration-act-south-africa"].replace(["?"], ["export-absent"])

#Steven Ohms
#this section of the code will turn all the vallues in the dataframes into numeric values
#all values are saved as str in the first place
#we will turn them into numeric

breast_cancer_dataset['concavity'] = breast_cancer_dataset['concavity'].astype(float)
#vote_dataset = vote_dataset.applymap(str)

#Gak Roppongi
#glass, iris, and  soybean don't have the missing value

#this function does mean-filling of the dataset for the missing value
#df is the dataframe we manipulate
#attribute is the attribute in the dataframe we are manipulating

def mean_filling(df, attribute):
  df[attribute].replace(np.nan, df[attribute].mean())
  return df

breast_cancer_dataset = mean_filling(breast_cancer_dataset, "concavity")

#Gak Roppongi
#this function implements the one-hot encoding
#df is the dataset we manipulate
#attribute is the attribute that we manipulate in str
#returns the one-hot encoded dataframe

def onehot(df, attribute):
  # Get one hot encoding of columns B
  one_hot = pd.get_dummies(df[attribute])
  # Drop column B as it is now encoded
  df = df.drop(attribute,axis = 1)
  # Join the encoded df
  df = df.join(one_hot)
  return df

breast_cancer_dataset = onehot(breast_cancer_dataset, "class")

glass_dataset = onehot(glass_dataset, "type of glass")

iris_dataset = onehot(iris_dataset, "class")

soybean_dataset = onehot(soybean_dataset, "roots")

vote_dataset = onehot(vote_dataset, "class name")
vote_dataset = onehot(vote_dataset, "handicapped-infants")
vote_dataset = onehot(vote_dataset, "water-project-cost-sharing")
vote_dataset = onehot(vote_dataset, "adoption-of-the-budget-resolution")
vote_dataset = onehot(vote_dataset, "physician-fee-freeze")
vote_dataset = onehot(vote_dataset, "el-salvador-aid")
vote_dataset = onehot(vote_dataset, "religious-groups-in-schools")
vote_dataset = onehot(vote_dataset, "anti-satellite-test-ban")
vote_dataset = onehot(vote_dataset, "aid-to-nicaraguan-contras")
vote_dataset = onehot(vote_dataset, "mx-missile")
vote_dataset = onehot(vote_dataset, "immigration")
vote_dataset = onehot(vote_dataset, "synfuels-corporation-cutback")
vote_dataset = onehot(vote_dataset, "education-spending")
vote_dataset = onehot(vote_dataset, "superfund-right-to-sue")
vote_dataset = onehot(vote_dataset, "crime")
vote_dataset = onehot(vote_dataset, "duty-free-exports")
vote_dataset = onehot(vote_dataset, "export-administration-act-south-africa")

#Steven Ohms
#this section of the code will normalize the dataset
#the function will take df and attribute
#df is the dataframe we are manipulating
#attribute is the attribute we are normalizing
#this is the z-score/standard score normalization

def normalize(df, attribute):
  """
  mean = df[attribute].mean()

  total = 0
  for i in df[attribute]:
    total = total + (i - mean)**2

  variance = total/len(df[attribute])
  std_dev = math.sqrt(variance)

  df[attribute] = (df[attribute] - mean)/std_dev
  """
  df = (df-df.min())/(df.max() - df.min())

  return df


breast_cancer_dataset = normalize(breast_cancer_dataset, "radius")
breast_cancer_dataset = normalize(breast_cancer_dataset, "texture")
breast_cancer_dataset = normalize(breast_cancer_dataset, "perimeter")
breast_cancer_dataset = normalize(breast_cancer_dataset, "area")
breast_cancer_dataset = normalize(breast_cancer_dataset, "smoothness")
breast_cancer_dataset = normalize(breast_cancer_dataset, "compactness")
breast_cancer_dataset = normalize(breast_cancer_dataset, "concavity")
breast_cancer_dataset = normalize(breast_cancer_dataset, "concave points")
breast_cancer_dataset = normalize(breast_cancer_dataset, "symmetry")
breast_cancer_dataset = normalize(breast_cancer_dataset, "fractal dimension")

glass_dataset = normalize(glass_dataset, "RI")
glass_dataset = normalize(glass_dataset, "Na")
glass_dataset = normalize(glass_dataset, "Mg")
glass_dataset = normalize(glass_dataset, "Al")
glass_dataset = normalize(glass_dataset, "Si")
glass_dataset = normalize(glass_dataset, "K")
glass_dataset = normalize(glass_dataset, "Ca")
glass_dataset = normalize(glass_dataset, "Ba")
glass_dataset = normalize(glass_dataset, "Fe")

iris_dataset = normalize(iris_dataset, "sepal length")
iris_dataset = normalize(iris_dataset, "sepal width")
iris_dataset = normalize(iris_dataset, "petal length")
iris_dataset = normalize(iris_dataset, "petal width")

#Steven Ohms
#this code descretizes the previously normalized data to make it so our algorithm can read the data
#the first hyperparameter is we have 5 categories for the range of 0.2
#we will tune this hyperparameter for 2 categories(0.5), 4 categories(0.25), 5 categories(0.2), and 8 categories(0.125).
'''
def discretize(df, att_name):
  """
  #2 categories for the range of 0.5
  df.loc[df[att_name].between(.5, 1, 'right'), att_name] = 2
  df.loc[df[att_name].between(0, .5, 'both'), att_name] = 1
  """
 
  """
  #4 categories for the range of 0.25
  f.loc[df[att_name].between(.75, 1, 'right'), att_name] = 4
  df.loc[df[att_name].between(.5, .75, 'right'), att_name] = 3
  df.loc[df[att_name].between(.25, .5, 'right'), att_name] = 2
  df.loc[df[att_name].between(0, .25, 'both'), att_name] = 1
  """
 
  #5 categories for the range of 0.2
  df.loc[df[att_name].between(.8, 1, 'right'), att_name] = 5
  df.loc[df[att_name].between(.6, .8, 'right'), att_name] = 4
  df.loc[df[att_name].between(.4, .6, 'right'), att_name] = 3
  df.loc[df[att_name].between(.2, .4, 'right'), att_name] = 2
  df.loc[df[att_name].between(0, .2, 'both'), att_name] = 1
 
  """
  #8 categories for the range of 0.125
  df.loc[df[att_name].between(.875, 1, 'right'), att_name] = 8
  df.loc[df[att_name].between(.75, .875, 'right'), att_name] = 7
  df.loc[df[att_name].between(.625, .75, 'right'), att_name] = 6
  df.loc[df[att_name].between(.5, .625, 'right'), att_name] = 5
  df.loc[df[att_name].between(.375, .5, 'right'), att_name] = 4
  df.loc[df[att_name].between(.25, .375, 'right'), att_name] = 3
  df.loc[df[att_name].between(.125, .25, 'right'), att_name] = 2
  df.loc[df[att_name].between(0, .125, 'both'), att_name] = 1
  """
  
 
  return df
  '''

def discretize2(df, att_name):
    
    df.loc[df[att_name].between(np.percentile(df[att_name],[50])[0], 1, 'right'), att_name] = 2
    df.loc[df[att_name].between(0, np.percentile(df[att_name],[50])[0], 'both'), att_name] = 1
 
 
def discretize5(df, att_name):
    
    df.loc[df[att_name].between(np.percentile(df[att_name],[80])[0], 1, 'right'), att_name] = 5
    df.loc[df[att_name].between(np.percentile(df[att_name],[60])[0], np.percentile(df[att_name],[80])[0], 'both'), att_name] = 4 
    df.loc[df[att_name].between(np.percentile(df[att_name],[40])[0], np.percentile(df[att_name],[60])[0], 'both'), att_name] = 3
    df.loc[df[att_name].between(np.percentile(df[att_name],[20])[0], np.percentile(df[att_name],[40])[0], 'both'), att_name] = 2
    df.loc[df[att_name].between(0, np.percentile(df[att_name],[20])[0], 'both'), att_name] = 1  
 
def discretize10(df, att_name):
    
    df.loc[df[att_name].between(np.percentile(df[att_name],[90])[0], 1, 'right'), att_name] = 10
    df.loc[df[att_name].between(np.percentile(df[att_name],[80])[0], np.percentile(df[att_name],[90])[0], 'both'), att_name] = 9 
    df.loc[df[att_name].between(np.percentile(df[att_name],[70])[0], np.percentile(df[att_name],[80])[0], 'both'), att_name] = 8
    df.loc[df[att_name].between(np.percentile(df[att_name],[60])[0], np.percentile(df[att_name],[70])[0], 'both'), att_name] = 7
    df.loc[df[att_name].between(np.percentile(df[att_name],[50])[0], np.percentile(df[att_name],[60])[0], 'both'), att_name] = 6 
    df.loc[df[att_name].between(np.percentile(df[att_name],[40])[0], np.percentile(df[att_name],[50])[0], 'both'), att_name] = 5
    df.loc[df[att_name].between(np.percentile(df[att_name],[30])[0], np.percentile(df[att_name],[40])[0], 'both'), att_name] = 4
    df.loc[df[att_name].between(np.percentile(df[att_name],[20])[0], np.percentile(df[att_name],[30])[0], 'both'), att_name] = 3 
    df.loc[df[att_name].between(np.percentile(df[att_name],[10])[0], np.percentile(df[att_name],[20])[0], 'both'), att_name] = 2
    df.loc[df[att_name].between(0, np.percentile(df[att_name],[10])[0], 'both'), att_name] = 1   
 
 
def discretize20(df, att_name):
  df.loc[df[att_name].between(np.percentile(df[att_name],[95])[0], 1, 'right'), att_name] = 20
  df.loc[df[att_name].between(np.percentile(df[att_name],[90])[0], np.percentile(df[att_name],[95])[0], 'both'), att_name] = 19 
  df.loc[df[att_name].between(np.percentile(df[att_name],[85])[0], np.percentile(df[att_name],[90])[0], 'both'), att_name] = 18
  df.loc[df[att_name].between(np.percentile(df[att_name],[80])[0], np.percentile(df[att_name],[85])[0], 'both'), att_name] = 17
  df.loc[df[att_name].between(np.percentile(df[att_name],[75])[0], np.percentile(df[att_name],[80])[0], 'both'), att_name] = 16 
  df.loc[df[att_name].between(np.percentile(df[att_name],[70])[0], np.percentile(df[att_name],[75])[0], 'both'), att_name] = 15
  df.loc[df[att_name].between(np.percentile(df[att_name],[65])[0], np.percentile(df[att_name],[70])[0], 'both'), att_name] = 14
  df.loc[df[att_name].between(np.percentile(df[att_name],[60])[0], np.percentile(df[att_name],[65])[0], 'both'), att_name] = 13 
  df.loc[df[att_name].between(np.percentile(df[att_name],[55])[0], np.percentile(df[att_name],[60])[0], 'both'), att_name] = 12
  df.loc[df[att_name].between(np.percentile(df[att_name],[50])[0], np.percentile(df[att_name],[55])[0], 'both'), att_name] = 11 
  df.loc[df[att_name].between(np.percentile(df[att_name],[45])[0], np.percentile(df[att_name],[50])[0], 'both'), att_name] = 10
  df.loc[df[att_name].between(np.percentile(df[att_name],[40])[0], np.percentile(df[att_name],[45])[0], 'both'), att_name] = 9
  df.loc[df[att_name].between(np.percentile(df[att_name],[35])[0], np.percentile(df[att_name],[40])[0], 'both'), att_name] = 8 
  df.loc[df[att_name].between(np.percentile(df[att_name],[30])[0], np.percentile(df[att_name],[35])[0], 'both'), att_name] = 7
  df.loc[df[att_name].between(np.percentile(df[att_name],[25])[0], np.percentile(df[att_name],[30])[0], 'both'), att_name] = 6
  df.loc[df[att_name].between(np.percentile(df[att_name],[20])[0], np.percentile(df[att_name],[25])[0], 'both'), att_name] = 5 
  df.loc[df[att_name].between(np.percentile(df[att_name],[15])[0], np.percentile(df[att_name],[20])[0], 'both'), att_name] = 4
  df.loc[df[att_name].between(np.percentile(df[att_name],[10])[0], np.percentile(df[att_name],[15])[0], 'both'), att_name] = 3
  df.loc[df[att_name].between(np.percentile(df[att_name],[5])[0], np.percentile(df[att_name],[10])[0], 'both'), att_name] = 2 
  df.loc[df[att_name].between(0, np.percentile(df[att_name],[5])[0], 'both'), att_name] = 1
 
discretize5(glass_dataset, "id")
discretize10(glass_dataset, "RI")
discretize2(glass_dataset, "Na")
discretize2(glass_dataset, "Mg")
discretize10(glass_dataset, "Al")
discretize10(glass_dataset, "Si")
discretize10(glass_dataset, "K")
discretize10(glass_dataset, "Ca")
discretize10(glass_dataset, "Ba")
discretize2(glass_dataset, "Fe")
 
discretize5(iris_dataset, "sepal length")
discretize5(iris_dataset, "sepal width")
discretize2(iris_dataset, "petal length")
discretize5(iris_dataset, "petal width")

#Gak Roppongi
"""
shuffling requires 10% of attributes values to be shuffled from each dataset
randomization will pick up the 10% of the attribute 
and shuffle the values inside the attribute
so that it will be 10% shuffled overall
"""

def shuffle(df, class_name):
  pickuped = []
  number_of_shuffled_attributes = len(df.columns) - len(class_name)
  number_of_attributes_to_pick_up = math.ceil(number_of_shuffled_attributes)

  for i in range(number_of_attributes_to_pick_up):
    index_of_attribute_to_be_shuffled = random.randint(0, number_of_attributes_to_pick_up) #<- the attribute to be shuffled is picked here

    while index_of_attribute_to_be_shuffled in pickuped:
      index_of_attribute_to_be_shuffled = random.randint(0, number_of_attributes_to_pick_up)

    df.columns[index_of_attribute_to_be_shuffled]
    shuffled_column = df[df.columns[index_of_attribute_to_be_shuffled]].sample(frac=1, random_state=1).reset_index()
    df[df.columns[index_of_attribute_to_be_shuffled]] = shuffled_column[df.columns[index_of_attribute_to_be_shuffled]]
    pickuped.append(index_of_attribute_to_be_shuffled)
    
  return df

#Steven Ohms
#merges all the portions together to create a testing set
 
def train_merge(one, two, three, four, five, six, seven, eight, nine):
  final_train = pd.merge(one, two, how="outer")
  final_train = pd.merge(final_train, three, how="outer")
  final_train = pd.merge(final_train, four, how="outer")
  final_train = pd.merge(final_train, five, how="outer")
  final_train = pd.merge(final_train, six, how="outer")
  final_train = pd.merge(final_train, seven, how="outer")
  final_train = pd.merge(final_train, eight, how="outer")
  final_train = pd.merge(final_train, nine, how="outer")
 
  return final_train

#Steven Ohms
#this section of the code will divide each original dataset into several sets
#each training sets have equal numbers of instances from each class

#breast_cancer_dataset has 458 from 2 and 241 from 4
#glass_dataset has 70 from 1, 76 from 2, 17 from 3, 0 from 4, 13 from 5, 9 from 6, and 29 from 7
#iris_dataset has 50 from Iris-setosa, 50 from Iris-versicolor, and 50 from Iris-virginica
#soybean_dataset has 56 from D1, 55 from D2, 82 from D3, and 112 from D4
#vote_dataset has 168 from republican, and 267 from democrat

i1 = iris_dataset.iloc[:5]
i2 = iris_dataset.iloc[5:10]
i3 = iris_dataset.iloc[10:15]
i4 = iris_dataset.iloc[15:20]
i5 = iris_dataset.iloc[20:25]
i6 = iris_dataset.iloc[25:30]
i7 = iris_dataset.iloc[30:35]
i8 = iris_dataset.iloc[35:40]
i9 = iris_dataset.iloc[40:45]
i10 = iris_dataset.iloc[45:50]

i11 = iris_dataset.iloc[50:55]
i12 = iris_dataset.iloc[55:60]
i13 = iris_dataset.iloc[60:65]
i14 = iris_dataset.iloc[65:70]
i15 = iris_dataset.iloc[70:75]
i16 = iris_dataset.iloc[75:80]
i17 = iris_dataset.iloc[80:85]
i18 = iris_dataset.iloc[85:90]
i19 = iris_dataset.iloc[90:95]
i20 = iris_dataset.iloc[95:100]

i21 = iris_dataset.iloc[100:105]
i22 = iris_dataset.iloc[105:110]
i23 = iris_dataset.iloc[110:115]
i24 = iris_dataset.iloc[115:120]
i25 = iris_dataset.iloc[120:125]
i26 = iris_dataset.iloc[125:130]
i27 = iris_dataset.iloc[130:135]
i28 = iris_dataset.iloc[135:140]
i29 = iris_dataset.iloc[140:145]
i30 = iris_dataset.iloc[145:150]

iris_one = pd.merge(i1, i11, how = "outer")
iris_one = pd.merge(iris_one, i21, how = "outer")

iris_two = pd.merge(i2, i12, how = "outer")
iris_two = pd.merge(iris_two, i22, how = "outer")

iris_three = pd.merge(i3, i13, how = "outer")
iris_three = pd.merge(iris_three, i23, how = "outer")

iris_four = pd.merge(i4, i14, how = "outer")
iris_four = pd.merge(iris_four, i24, how = "outer")

iris_five = pd.merge(i5, i15, how = "outer")
iris_five = pd.merge(iris_five, i25, how = "outer")

iris_six = pd.merge(i6, i16, how = "outer")
iris_six = pd.merge(iris_six, i26, how = "outer")

iris_seven = pd.merge(i7, i17, how = "outer")
iris_seven = pd.merge(iris_seven, i27, how = "outer")

iris_eight = pd.merge(i8, i18, how = "outer")
iris_eight = pd.merge(iris_eight, i28, how = "outer")

iris_nine = pd.merge(i9, i19, how = "outer")
iris_nine = pd.merge(iris_nine, i29, how = "outer")

iris_ten = pd.merge(i10, i20, how = "outer")
iris_ten = pd.merge(iris_ten, i30, how = "outer")

#iris dataset has three sets of 50 for each class
#we want three training sets
#each training class gets divided into 17/17/16

#Steven Ohms
#soybean_dataset has 10, 10, 10, 17
#we want 10 training sets
s1 = soybean_dataset.iloc[:1]
s2 = soybean_dataset.iloc[1:2]
s3 = soybean_dataset.iloc[2:3]
s4 = soybean_dataset.iloc[3:4]
s5 = soybean_dataset.iloc[4:5]
s6 = soybean_dataset.iloc[5:6]
s7 = soybean_dataset.iloc[6:7]
s8 = soybean_dataset.iloc[7:8]
s9 = soybean_dataset.iloc[8:9]
s10 = soybean_dataset.iloc[9:10]
 
s11 = soybean_dataset.iloc[10:11]
s12 = soybean_dataset.iloc[11:12]
s13 = soybean_dataset.iloc[12:13]
s14 = soybean_dataset.iloc[13:14]
s15 = soybean_dataset.iloc[14:15]
s16 = soybean_dataset.iloc[15:16]
s17 = soybean_dataset.iloc[16:17]
s18 = soybean_dataset.iloc[17:18]
s19 = soybean_dataset.iloc[18:19]
s20 = soybean_dataset.iloc[19:20]
 
s21 = soybean_dataset.iloc[20:21]
s22 = soybean_dataset.iloc[21:22]
s23 = soybean_dataset.iloc[22:23]
s24 = soybean_dataset.iloc[23:24]
s25 = soybean_dataset.iloc[24:25]
s26 = soybean_dataset.iloc[25:26]
s27 = soybean_dataset.iloc[26:27]
s28 = soybean_dataset.iloc[27:28]
s29 = soybean_dataset.iloc[28:29]
s30 = soybean_dataset.iloc[29:30]
 
s31 = soybean_dataset.iloc[30:31]
s32 = soybean_dataset.iloc[31:32]
s33 = soybean_dataset.iloc[32:33]
s34 = soybean_dataset.iloc[33:35]
s35 = soybean_dataset.iloc[35:37]
s36 = soybean_dataset.iloc[37:39]
s37 = soybean_dataset.iloc[39:41]
s38 = soybean_dataset.iloc[41:43]
s39 = soybean_dataset.iloc[43:45]
s40 = soybean_dataset.iloc[45:47]

soybean_one = pd.merge(s1, s11, how = "outer")
soybean_one = pd.merge(soybean_one, s21, how = "outer")
soybean_one = pd.merge(soybean_one, s31, how = "outer")

soybean_two = pd.merge(s2, s12, how = "outer")
soybean_two = pd.merge(soybean_two, s22, how = "outer")
soybean_two = pd.merge(soybean_two, s32, how = "outer")

soybean_three = pd.merge(s3, s13, how = "outer")
soybean_three = pd.merge(soybean_three, s23, how = "outer")
soybean_three = pd.merge(soybean_three, s33, how = "outer")

soybean_four = pd.merge(s4, s14, how = "outer")
soybean_four = pd.merge(soybean_four, s24, how = "outer")
soybean_four = pd.merge(soybean_four, s34, how = "outer")

soybean_five = pd.merge(s5, s15, how = "outer")
soybean_five = pd.merge(soybean_five, s25, how = "outer")
soybean_five = pd.merge(soybean_five, s35, how = "outer")

soybean_six = pd.merge(s6, s16, how = "outer")
soybean_six = pd.merge(soybean_six, s26, how = "outer")
soybean_six = pd.merge(soybean_six, s36, how = "outer")

soybean_seven = pd.merge(s7, s17, how = "outer")
soybean_seven = pd.merge(soybean_seven, s27, how = "outer")
soybean_seven = pd.merge(soybean_seven, s37, how = "outer")

soybean_eight = pd.merge(s8, s18, how = "outer")
soybean_eight = pd.merge(soybean_eight, s28, how = "outer")
soybean_eight = pd.merge(soybean_eight, s38, how = "outer")

soybean_nine = pd.merge(s9, s19, how = "outer")
soybean_nine = pd.merge(soybean_nine, s29, how = "outer")
soybean_nine = pd.merge(soybean_nine, s39, how = "outer")

soybean_ten = pd.merge(s10, s20, how = "outer")
soybean_ten = pd.merge(soybean_ten, s30, how = "outer")
soybean_ten = pd.merge(soybean_ten, s40, how = "outer")

#Gak Roppongi
#vote dataset has two sets, democrat being 168 instances and republican being 267
#we want three training sets 
#each training class will have 89 democrats, and 56 republicans
 
v_1 = vote_dataset.iloc[:26]
v_2 = vote_dataset.iloc[26:52]
v_3 = vote_dataset.iloc[52:78]
v_4 = vote_dataset.iloc[78:105]
v_5 = vote_dataset.iloc[105:132]
v_6 = vote_dataset.iloc[132:159]
v_7 = vote_dataset.iloc[159:186]
v_8 = vote_dataset.iloc[186:213]
v_9 = vote_dataset.iloc[213:240]
v_10 = vote_dataset.iloc[240:267]

v_11 = vote_dataset.iloc[267:283]
v_12 = vote_dataset.iloc[283:299]
v_13 = vote_dataset.iloc[299:316]
v_14 = vote_dataset.iloc[316:333]
v_15 = vote_dataset.iloc[333:350]
v_16 = vote_dataset.iloc[350:367]
v_17 = vote_dataset.iloc[367:384]
v_18 = vote_dataset.iloc[384:401]
v_19 = vote_dataset.iloc[401:418]
v_20 = vote_dataset.iloc[418:435]

vote_one = pd.merge(v_1, v_11, how = "outer")
vote_two = pd.merge(v_2, v_12, how = "outer")
vote_three = pd.merge(v_3, v_13, how = "outer")
vote_four = pd.merge(v_4, v_14, how = "outer")
vote_five = pd.merge(v_5, v_15, how = "outer")
vote_six = pd.merge(v_6, v_16, how = "outer")
vote_seven = pd.merge(v_7, v_17, how = "outer")
vote_eight = pd.merge(v_8, v_18, how = "outer")
vote_nine = pd.merge(v_9, v_19, how = "outer")
vote_ten = pd.merge(v_10, v_20, how = "outer")

#Gak Roppongi
#we have 458 and 241 from each class
#we want to have three training sets
#class one should be divided into 153, 153, 152
#class two should be divided into 80, 80, 81
#.iloc[a:b] does not contain a value so it should be a+1 through b
#we will combine one + four, two + five, and three + six

b_1 = breast_cancer_dataset.iloc[:45]
b_2 = breast_cancer_dataset.iloc[45:90]
b_3 = breast_cancer_dataset.iloc[90:136]
b_4 = breast_cancer_dataset.iloc[136:182]
b_5 = breast_cancer_dataset.iloc[182:228]
b_6 = breast_cancer_dataset.iloc[228:274]
b_7 = breast_cancer_dataset.iloc[274:320]
b_8 = breast_cancer_dataset.iloc[320:366]
b_9 = breast_cancer_dataset.iloc[366:412]
b_10 = breast_cancer_dataset.iloc[412:458]
 
b_11 = breast_cancer_dataset.iloc[458:482]
b_12 = breast_cancer_dataset.iloc[482:506]
b_13 = breast_cancer_dataset.iloc[506:530]
b_14 = breast_cancer_dataset.iloc[530:554]
b_15 = breast_cancer_dataset.iloc[554:578]
b_16 = breast_cancer_dataset.iloc[578:602]
b_17 = breast_cancer_dataset.iloc[602:626]
b_18 = breast_cancer_dataset.iloc[626:650]
b_19 = breast_cancer_dataset.iloc[650:674]
b_20 = breast_cancer_dataset.iloc[674:699]
 
breast_one = pd.merge(b_1, b_11, how="outer")
breast_two = pd.merge(b_2, b_12, how="outer")
breast_three = pd.merge(b_3, b_13, how="outer")
breast_four = pd.merge(b_4, b_14, how="outer")
breast_five = pd.merge(b_5, b_15, how="outer")
breast_six = pd.merge(b_6, b_16, how="outer")
breast_seven = pd.merge(b_7, b_17, how="outer")
breast_eight = pd.merge(b_8, b_18, how="outer")
breast_nine = pd.merge(b_9, b_19, how="outer")
breast_ten = pd.merge(b_10, b_20, how="outer")

#Steven Ohms
#we have 70, 76, 17, 0, 13, 9, and 29 from each class
#we want to have ten training sets
#.iloc[a:b] does not contain a value so it should be a+1 through b

g1 = glass_dataset.iloc[:7]
g2 = glass_dataset.iloc[7:14]
g3 = glass_dataset.iloc[14:21]
g4 = glass_dataset.iloc[21:28]
g5 = glass_dataset.iloc[28:35]
g6 = glass_dataset.iloc[35:42]
g7 = glass_dataset.iloc[42:49]
g8 = glass_dataset.iloc[49:56]
g9 = glass_dataset.iloc[56:63]
g10 = glass_dataset.iloc[63:70]

g11 = glass_dataset.iloc[70:77]
g12 = glass_dataset.iloc[77:84]
g13 = glass_dataset.iloc[84:91]
g14 = glass_dataset.iloc[91:98]
g15 = glass_dataset.iloc[98:106]
g16 = glass_dataset.iloc[106:114]
g17 = glass_dataset.iloc[114:122]
g18 = glass_dataset.iloc[122:130]
g19 = glass_dataset.iloc[130:138]
g20 = glass_dataset.iloc[138:146]

g21 = glass_dataset.iloc[146:148]
g22 = glass_dataset.iloc[148:150]
g23 = glass_dataset.iloc[150:152]
g24 = glass_dataset.iloc[152:154]
g25 = glass_dataset.iloc[154:156]
g26 = glass_dataset.iloc[156:158]
g27 = glass_dataset.iloc[158:160]
g28 = glass_dataset.iloc[160:161]
g29 = glass_dataset.iloc[161:162]
g30 = glass_dataset.iloc[162:163]

g31 = glass_dataset.iloc[163:164]
g32 = glass_dataset.iloc[164:165]
g33 = glass_dataset.iloc[165:166]
g34 = glass_dataset.iloc[166:167]
g35 = glass_dataset.iloc[167:168]
g36 = glass_dataset.iloc[168:169]
g37 = glass_dataset.iloc[169:170]
g38 = glass_dataset.iloc[170:172]
g39 = glass_dataset.iloc[172:174]
g40 = glass_dataset.iloc[174:176]

g41 = glass_dataset.iloc[176:177]
g42 = glass_dataset.iloc[177:178]
g43 = glass_dataset.iloc[178:179]
g44 = glass_dataset.iloc[179:180]
g45 = glass_dataset.iloc[180:181]
g46 = glass_dataset.iloc[181:182]
g47 = glass_dataset.iloc[182:183]
g48 = glass_dataset.iloc[183:184]
g49 = glass_dataset.iloc[184:185]
g50 = glass_dataset.iloc[185:185]

g51 = glass_dataset.iloc[185:188]
g52 = glass_dataset.iloc[188:191]
g53 = glass_dataset.iloc[191:194]
g54 = glass_dataset.iloc[194:197]
g55 = glass_dataset.iloc[197:200]
g56 = glass_dataset.iloc[200:203]
g57 = glass_dataset.iloc[203:206]
g58 = glass_dataset.iloc[206:209]
g59 = glass_dataset.iloc[209:211]
g60 = glass_dataset.iloc[211:214]

glass_one = pd.merge(g1, g11, how="outer")
glass_one = pd.merge(glass_one, g21, how="outer")
glass_one = pd.merge(glass_one, g31, how="outer")
glass_one = pd.merge(glass_one, g41, how="outer")
glass_one = pd.merge(glass_one, g51, how="outer")

glass_two = pd.merge(g2, g12, how="outer")
glass_two = pd.merge(glass_two, g22, how="outer")
glass_two = pd.merge(glass_two, g32, how="outer")
glass_two = pd.merge(glass_two, g42, how="outer")
glass_two = pd.merge(glass_two, g52, how="outer")

glass_three = pd.merge(g3, g13, how="outer")
glass_three = pd.merge(glass_three, g23, how="outer")
glass_three = pd.merge(glass_three, g33, how="outer")
glass_three = pd.merge(glass_three, g43, how="outer")
glass_three = pd.merge(glass_three, g53, how="outer")

glass_four = pd.merge(g4, g14, how="outer")
glass_four = pd.merge(glass_four, g24, how="outer")
glass_four = pd.merge(glass_four, g34, how="outer")
glass_four = pd.merge(glass_four, g44, how="outer")
glass_four = pd.merge(glass_four, g54, how="outer")

glass_five = pd.merge(g5, g15, how="outer")
glass_five = pd.merge(glass_five, g25, how="outer")
glass_five = pd.merge(glass_five, g35, how="outer")
glass_five = pd.merge(glass_five, g45, how="outer")
glass_five = pd.merge(glass_five, g55, how="outer")

glass_six = pd.merge(g6, g16, how="outer")
glass_six = pd.merge(glass_six, g26, how="outer")
glass_six = pd.merge(glass_six, g36, how="outer")
glass_six = pd.merge(glass_six, g46, how="outer")
glass_six = pd.merge(glass_six, g56, how="outer")

glass_seven = pd.merge(g7, g17, how="outer")
glass_seven = pd.merge(glass_seven, g27, how="outer")
glass_seven = pd.merge(glass_seven, g37, how="outer")
glass_seven = pd.merge(glass_seven, g47, how="outer")
glass_seven = pd.merge(glass_seven, g57, how="outer")

glass_eight = pd.merge(g8, g18, how="outer")
glass_eight = pd.merge(glass_eight, g28, how="outer")
glass_eight = pd.merge(glass_eight, g38, how="outer")
glass_eight = pd.merge(glass_eight, g48, how="outer")
glass_eight = pd.merge(glass_eight, g58, how="outer")

glass_nine = pd.merge(g9, g19, how="outer")
glass_nine = pd.merge(glass_nine, g29, how="outer")
glass_nine = pd.merge(glass_nine, g39, how="outer")
glass_nine = pd.merge(glass_nine, g49, how="outer")
glass_nine = pd.merge(glass_nine, g59, how="outer")

glass_ten = pd.merge(g10, g20, how="outer")
glass_ten = pd.merge(glass_ten, g30, how="outer")
glass_ten = pd.merge(glass_ten, g40, how="outer")
glass_ten = pd.merge(glass_ten, g50, how="outer")
glass_ten = pd.merge(glass_ten, g60, how="outer")

#Steven Ohms
#first part
#Q(C = ci) = (number of instances in each class)/(number of instances in training sets)

def Q(df, attribute):
  value = 1.0
  occurence = df[attribute].value_counts()[value]
  return occurence / df.shape[0]

#Steven Ohms
#second part
#F (Aj = ak) = # {(xAj = ak) and (x = ci)} + 1/ Nci + d

def F(dftrain, attribute_name, attribute_value, class_name, len_class_name):
  sum_count = 0
  N = 0
  d = len(dftrain.columns) - len_class_name
  for k in dftrain.index:
    if ((dftrain[attribute_name][k] == attribute_value) and (dftrain[class_name][k] == 1)):
      sum_count = sum_count + 1
    if dftrain[class_name][k] == 1:
      N = N + 1

  numerator = sum_count + 1
  denominator = N + d
  F = numerator / denominator
  return F

#Gak Roppongi
"""
this function will return the C function
"""
def C(instance, dftrain, class_name, len_class_name):
  Q_X = Q(dftrain, class_name)
  f = 1
  
  for index, value in instance.items():
    f = f * F(dftrain, index, value, class_name, len_class_name)

  return Q_X*f

#Gak Roppongi
"""
this function will iterate through the rows of the training dataset (instances in the training dataset),
and for each instance, this will iterate through the classes.
this function will call def C for each combination of the instance in the training dataset and the class

probably need two df, one for testing, one for training)

param {dftest: the dataset we use as the test dataset, this should be a pandas dataframe
       dftrain: the dataset we use as the training dataset, this should be a pandas dataframe
       class_name: an array of classes that is in the dataset we use, this must be np.array
}

return {C: the probability of a certain instance in a dataset belongs to a certain class in a dataset,
        we should have the return for each instance in the test dataset
        this return should be a number
}
"""

def Class(dftest, dftrain, class_name):
  matrix = []

  for X in range (dftest.shape[0]): #<- maybe we should change this to for index, value dftest.items():, we want the index of the rows in the dataset
    P = -1
    predict = None
    actual = None

    for g in class_name: #<- g is the actual class name in the class_name array
      if dftest.loc[X][g] == 1.0 or dftest.loc[X][g] == 1: #<- this like of code sees if the attribute under the class name in the X row is labeled as 1 or not
        actual = g

    for h in class_name: #<- h is the actual class name and for each row, this line of code drops the columns of the attribute with the class name
      dftest.loc[X].drop(h)
    
    for i in range(len(class_name)):
      C_X = C(dftest.loc[X], dftrain, class_name[i], len(class_name))
      if P < C_X:
        P = C_X
        predict = class_name[i]
    
    #print(predict, actual)
    matrix.append([predict, actual])
  
  return matrix

#Steven Ohms
def zero_loss_func(result):
  correct = 0
  incorrect = 0
  for i in range(len(result)):
    if result[i][0] == result[i][1]:
      correct = correct+1
    elif result[i][0] != result[i][1]:
      incorrect = incorrect + 1
  
  return [correct, incorrect]

#Gak Roppongi
def confusion_matrix_breast_cancer(result):
  two_two = 0
  two_four = 0
  four_two = 0
  four_four = 0

  #predict_actual
  
  for i in result:
    
    if (i[0] == i[1]):
      if (i[1] == 2): #<- predict is 2 and actual is 2
        two_two += 1
      
      elif (i[1] == 4): #<- predict is 2 and actual is 2
        four_four += 1

    elif (i[0] != i[1]):
      if (i[1] == 2): #<- predict is 4 and actual is 2
        four_two += 1

      elif (i[1] == 4): #<- predict is 2 and actual is 4
        two_four += 1
  
    matrix = [[two_two, two_four], [four_two, four_four]]
  return matrix

#Gak Roppongi
def confusion_matrix_vote(result):
  repub_repub = 0
  repub_demo = 0
  demo_repub = 0
  demo_demo = 0

  #predict_actual
  #2 = republican
  #4 = democrat
  
  for i in result:
    
    if (i[0] == i[1]):
      if (i[1] == "republican"): #<- predict is repub and actual is repub
        repub_repub += 1
      
      elif (i[1] == "democrat"): #<- predict is demo and actual is demo
        demo_demo += 1

    elif (i[0] != i[1]):
      if (i[1] == "republican"): #<- predict is demo and actual is repub
        demo_repub += 1

      elif (i[1] == "democrat"): #<- predict is repub and actual is demo
        repub_demo += 1
  
    matrix = [[repub_repub, repub_demo], 
              [demo_repub, demo_demo]]
    
  return matrix

#Steven Ohms
def confusion_matrix_soybean(result):
  D1_D1 = 0
  D1_D2 = 0
  D1_D3 = 0
  D1_D4 = 0

  D2_D1 = 0
  D2_D2 = 0
  D2_D3 = 0
  D2_D4 = 0

  D3_D1 = 0
  D3_D2 = 0
  D3_D3 = 0
  D3_D4 = 0

  D4_D1 = 0
  D4_D2 = 0
  D4_D3 = 0
  D4_D4 = 0

  #predict_actual
  #classes are
  #D1
  #D2
  #D3
  #D4
  
  for i in result:
    """
    i[0] is the predicted value
    i[1] is the actual value
    """
    if (i[0] == "D1"):
      if (i[1] == "D1"):
        D1_D1 +=1

      elif (i[1] == "D2"):
        D1_D2 +=1

      elif (i[1] == "D3"):
        D1_D3 +=1

      elif (i[1] == "D4"):
        D1_D4 +=1

    elif (i[0] == "D2"):
      if (i[1] == "D1"):
        D2_D1 +=1

      elif (i[1] == "D2"):
        D2_D2 +=1

      elif (i[1] == "D3"):
        D2_D3 +=1

      elif (i[1] == "D4"):
        D2_D4 +=1

    elif (i[0] == "D3"):
      if (i[1] == "D1"):
        D3_D1 +=1

      elif (i[1] == "D2"):
        D3_D2 +=1

      elif (i[1] == "D3"):
        D3_D3 +=1

      elif (i[1] == "D4"):
        D3_D4 +=1

    elif (i[0] == "D4"):
      if (i[1] == "D1"):
        D4_D1 +=1

      elif (i[1] == "D2"):
        D4_D2 +=1

      elif (i[1] == "D3"):
        D4_D3 +=1

      elif (i[1] == "D4"):
        D4_D4 +=1
  
    matrix = [[D1_D1, D1_D2, D1_D3, D1_D4], 
              [D2_D1, D2_D2, D2_D3, D2_D4], 
              [D3_D1, D3_D2, D3_D3,D3_D4], 
              [D4_D1, D4_D2, D4_D3, D4_D4]]
    
  return matrix

#Gak Roppongi
def confusion_matrix_glass(result):
  one_one = 0
  one_two = 0
  one_three = 0
  one_five = 0
  one_six = 0
  one_seven = 0

  two_one = 0
  two_two = 0
  two_three = 0
  two_five = 0
  two_six = 0
  two_seven = 0

  three_one = 0
  three_two = 0
  three_three = 0
  three_five = 0
  three_six = 0
  three_seven = 0

  five_one = 0
  five_two = 0
  five_three = 0
  five_five = 0
  five_six = 0
  five_seven = 0

  six_one = 0
  six_two = 0
  six_three = 0
  six_five = 0
  six_six = 0
  six_seven = 0

  seven_one = 0
  seven_two = 0
  seven_three = 0
  seven_five = 0
  seven_six = 0
  seven_seven = 0

  #predict_actual
  #classes are
  #1
  #2
  #3
  #5
  #6
  #7
  
  for i in result:
    """
    i[0] is the predicted value
    i[1] is the actual value
    """
    if (i[0] == 1):
      if (i[1] == 1):
        one_one += 1

      elif (i[1] == 2):
        one_two += 1

      elif (i[1] == 3):
        one_three += 1

      elif (i[1] == 5):
        one_five += 1

      elif (i[1] == 6):
        one_six += 1

      elif (i[1] == 7):
        one_seven += 1

    elif (i[0] == 2):
      if (i[1] == 1):
        two_one += 1

      elif (i[1] == 2):
        two_two += 1

      elif (i[1] == 3):
        two_three += 1

      elif (i[1] == 5):
        two_five += 1

      elif (i[1] == 6):
        two_six += 1

      elif (i[1] == 7):
        two_seven += 1

    elif (i[0] == 3):
      if (i[1] == 1):
        three_one += 1

      elif (i[1] == 2):
        three_two += 1

      elif (i[1] == 3):
        three_three += 1

      elif (i[1] == 5):
        three_five += 1

      elif (i[1] == 6):
        three_six += 1

      elif (i[1] == 7):
        three_seven += 1

    elif (i[0] == 5):
      if (i[1] == 1):
        five_one += 1

      elif (i[1] == 2):
        five_two += 1

      elif (i[1] == 3):
        five_three += 1

      elif (i[1] == 5):
        five_five += 1

      elif (i[1] == 6):
        five_six += 1

      elif (i[1] == 7):
        five_seven += 1

    elif (i[0] == 6):
      if (i[1] == 1):
        six_one += 1

      elif (i[1] == 2):
        six_two += 1

      elif (i[1] == 3):
        six_three += 1

      elif (i[1] == 5):
        six_five += 1

      elif (i[1] == 6):
        six_six += 1

      elif (i[1] == 7):
        six_seven += 1

    elif (i[0] == 7):
      if (i[1] == 1):
        seven_one += 1

      elif (i[1] == 2):
        seven_two += 1

      elif (i[1] == 3):
        seven_three += 1

      elif (i[1] == 5):
        seven_five += 1

      elif (i[1] == 6):
        seven_six += 1

      elif (i[1] == 7):
        seven_seven += 1
  
    matrix = [[one_one, one_two, one_three, one_five, one_six, one_seven], 
              [two_one, two_two, two_three, two_five, two_six, two_seven], 
              [three_one, three_two, three_three, three_five, three_six, three_seven], 
              [five_one, five_two, five_three, five_five, five_six, five_seven],
              [six_one, six_two, six_three, six_five, six_six, six_seven],
              [seven_one, seven_two, seven_three, seven_five, seven_six, seven_seven]]
    
  return matrix

#Steven Ohms
def confusion_matrix_iris(result):
  setosa_setosa = 0
  setosa_versicolor = 0
  setosa_virginica = 0

  versicolor_setosa = 0
  versicolor_versicolor = 0
  versicolor_virginica = 0

  virginica_setosa = 0
  virginica_versicolor = 0
  virginica_virginica = 0

  #predict_actual
  #classes are
  #setosa
  #versicolor
  #virginica
  
  for i in result:
    """
    i[0] is the predicted value
    i[1] is the actual value
    """
    if (i[0] == "Iris-setosa"):
      if (i[1] == "Iris-setosa"):
        setosa_setosa += 1

      elif (i[1] == "Iris-versicolor"):
        setosa_versicolor += 1

      elif (i[1] == "Iris-virginica"):
        setosa_virginica += 1

    elif (i[0] == "Iris-versicolor"):
      if (i[1] == "Iris-setosa"):
        versicolor_setosa += 1

      elif (i[1] == "Iris-versicolor"):
        versicolor_versicolor += 1

      elif (i[1] == "Iris-virginica"):
        versicolor_virginica += 1

    elif (i[0] == "Iris-virginica"):
      if (i[1] == "Iris-setosa"):
        virginica_setosa += 1

      elif (i[1] == "Iris-versicolor"):
        virginica_versicolor += 1

      elif (i[1] == "Iris-virginica"):
        virginica_virginica += 1
  
    matrix = [[setosa_setosa, setosa_versicolor, setosa_virginica], 
              [versicolor_setosa, versicolor_versicolor, versicolor_virginica], 
              [virginica_setosa, virginica_versicolor, virginica_virginica]]
    
  return matrix

#Steven Ohms
#Class(test set, training set, class names)
#since each dataset is divided into 3, we will have 3 different combinations of those sets
#then the class name array is also defined as setname_class in numpy array
 
breast_training_one = shuffle(train_merge(breast_ten, breast_two, breast_three, breast_four, breast_five, breast_six, breast_seven, breast_eight, breast_nine), breast_class)
breast_training_two = shuffle(train_merge(breast_ten, breast_one, breast_three, breast_four, breast_five, breast_six, breast_seven, breast_eight, breast_nine), breast_class)
breast_training_three = shuffle(train_merge(breast_ten, breast_one, breast_two, breast_four, breast_five, breast_six, breast_seven, breast_eight, breast_nine), breast_class)
breast_training_four = shuffle(train_merge(breast_ten, breast_one, breast_two, breast_three, breast_five, breast_six, breast_seven, breast_eight, breast_nine), breast_class)
breast_training_five = shuffle(train_merge(breast_ten, breast_one, breast_two, breast_three, breast_four, breast_six, breast_seven, breast_eight, breast_nine), breast_class)
breast_training_six = shuffle(train_merge(breast_ten, breast_one, breast_two, breast_three, breast_four, breast_five, breast_seven, breast_eight, breast_nine), breast_class)
breast_training_seven = shuffle(train_merge(breast_ten, breast_one, breast_two, breast_three, breast_four, breast_five, breast_six, breast_eight, breast_nine), breast_class)
breast_training_eight = shuffle(train_merge(breast_ten, breast_one, breast_two, breast_three, breast_four, breast_five, breast_six, breast_seven, breast_nine), breast_class)
breast_training_nine = shuffle(train_merge(breast_ten, breast_one, breast_two, breast_three, breast_four, breast_five, breast_six, breast_seven, breast_eight), breast_class)
breast_training_ten = shuffle(train_merge(breast_one, breast_two, breast_three, breast_four, breast_five, breast_six, breast_seven, breast_eight, breast_nine), breast_class)
 
print("breast first training start")
result_breast_one = Class(breast_one, breast_training_one, breast_class)
print("breast second training start")
result_breast_two = Class(breast_two, breast_training_two, breast_class)
print("breast third training start")
result_breast_three = Class(breast_three, breast_training_three, breast_class)
print("breast fourth training start")
result_breast_four = Class(breast_four, breast_training_four, breast_class)
print("breast fifth training start")
result_breast_five = Class(breast_five, breast_training_five, breast_class)
print("breast sixth training start")
result_breast_six = Class(breast_six, breast_training_six, breast_class)
print("breast seventh training start")
result_breast_seven = Class(breast_seven, breast_training_seven, breast_class)
print("breast eighth training start")
result_breast_eight = Class(breast_eight, breast_training_eight, breast_class)
print("breast ninth training start")
result_breast_nine = Class(breast_nine, breast_training_nine, breast_class)
print("breast tenth training start")
result_breast_ten = Class(breast_ten, breast_training_ten, breast_class)

print(zero_loss_func(result_breast_one))
print(zero_loss_func(result_breast_two))
print(zero_loss_func(result_breast_three))
print(zero_loss_func(result_breast_four))
print(zero_loss_func(result_breast_five))
print(zero_loss_func(result_breast_six))
print(zero_loss_func(result_breast_seven))
print(zero_loss_func(result_breast_eight))
print(zero_loss_func(result_breast_nine))
print(zero_loss_func(result_breast_ten))

print(confusion_matrix_breast_cancer(result_breast_one))
print(confusion_matrix_breast_cancer(result_breast_two))
print(confusion_matrix_breast_cancer(result_breast_three))
print(confusion_matrix_breast_cancer(result_breast_four))
print(confusion_matrix_breast_cancer(result_breast_five))
print(confusion_matrix_breast_cancer(result_breast_six))
print(confusion_matrix_breast_cancer(result_breast_seven))
print(confusion_matrix_breast_cancer(result_breast_eight))
print(confusion_matrix_breast_cancer(result_breast_nine))
print(confusion_matrix_breast_cancer(result_breast_ten))

#Gak Roppongi
glass_training_one = shuffle(train_merge(glass_ten, glass_two, glass_three, glass_four, glass_five, glass_six, glass_seven, glass_eight, glass_nine), glass_class)
glass_training_two = shuffle(train_merge(glass_ten, glass_one, glass_three, glass_four, glass_five, glass_six, glass_seven, glass_eight, glass_nine), glass_class)
glass_training_three = shuffle(train_merge(glass_ten, glass_one, glass_two, glass_four, glass_five, glass_six, glass_seven, glass_eight, glass_nine), glass_class)
glass_training_four = shuffle(train_merge(glass_ten, glass_one, glass_two, glass_three, glass_five, glass_six, glass_seven, glass_eight, glass_nine), glass_class)
glass_training_five = shuffle(train_merge(glass_ten, glass_one, glass_two, glass_three, glass_four, glass_six, glass_seven, glass_eight, glass_nine), glass_class)
glass_training_six = shuffle(train_merge(glass_ten, glass_one, glass_two, glass_three, glass_four, glass_five, glass_seven, glass_eight, glass_nine), glass_class)
glass_training_seven = shuffle(train_merge(glass_ten, glass_one, glass_two, glass_three, glass_four, glass_five, glass_six, glass_eight, glass_nine), glass_class)
glass_training_eight = shuffle(train_merge(glass_ten, glass_one, glass_two, glass_three, glass_four, glass_five, glass_six, glass_seven, glass_nine), glass_class)
glass_training_nine = shuffle(train_merge(glass_ten, glass_one, glass_two, glass_three, glass_four, glass_five, glass_six, glass_seven, glass_eight), glass_class)
glass_training_ten = shuffle(train_merge(glass_one, glass_two, glass_three, glass_four, glass_five, glass_six, glass_seven, glass_eight, glass_nine), glass_class)
 
print("glass first training start")
result_glass_one = Class(glass_one, glass_training_one, glass_class)
print("glass second training start")
result_glass_two = Class(glass_two, glass_training_two, glass_class)
print("glass third training start")
result_glass_three = Class(glass_three, glass_training_three, glass_class)
print("glass fourth training start")
result_glass_four = Class(glass_four, glass_training_four, glass_class)
print("glass fifth training start")
result_glass_five = Class(glass_five, glass_training_five, glass_class)
print("glass sixth training start")
result_glass_six = Class(glass_six, glass_training_six, glass_class)
print("glass seventh training start")
result_glass_seven = Class(glass_seven, glass_training_seven, glass_class)
print("glass eighth training start")
result_glass_eight = Class(glass_eight, glass_training_eight, glass_class)
print("glass ninth training start")
result_glass_nine = Class(glass_nine, glass_training_nine, glass_class)
print("glass tenth training start")
result_glass_ten = Class(glass_ten, glass_training_ten, glass_class)
 
print(zero_loss_func(result_glass_one))
print(zero_loss_func(result_glass_two))
print(zero_loss_func(result_glass_three))
print(zero_loss_func(result_glass_four))
print(zero_loss_func(result_glass_five))
print(zero_loss_func(result_glass_six))
print(zero_loss_func(result_glass_seven))
print(zero_loss_func(result_glass_eight))
print(zero_loss_func(result_glass_nine))
print(zero_loss_func(result_glass_ten))

print(confusion_matrix_glass(result_glass_one))
print(confusion_matrix_glass(result_glass_two))
print(confusion_matrix_glass(result_glass_three))
print(confusion_matrix_glass(result_glass_four))
print(confusion_matrix_glass(result_glass_five))
print(confusion_matrix_glass(result_glass_six))
print(confusion_matrix_glass(result_glass_seven))
print(confusion_matrix_glass(result_glass_eight))
print(confusion_matrix_glass(result_glass_nine))
print(confusion_matrix_glass(result_glass_ten))

#Steven Ohms
"""
F-score = (TP)/(TP+0.5(FP+FN))
"""
def F_score6x6(matrix):
  TP_1 = matrix[0][0]
  TN_1 = matrix[1][1] + matrix[1][2] + matrix[1][3] + matrix[1][4] + matrix[1][5] + matrix[2][1] + matrix[2][2] + matrix[2][3] + matrix[2][4] + matrix[2][5] + matrix[3][1] + matrix[3][2] + matrix[3][3] + matrix[3][4] + matrix[3][5] + matrix[4][1] + matrix[4][2] + matrix[4][3] + matrix[4][4] + matrix[4][5] + matrix[5][1] + matrix[5][2] + matrix[5][3] + matrix[5][4] + matrix[5][5]
  FP_1 = matrix[0][1] + matrix[0][2] + matrix[0][3] + matrix[0][4] + matrix[0][5]
  FN_1 = matrix[1][0] + matrix[2][0] + matrix[3][0] + matrix[4][0] + matrix[4][0]

  TP_2 = matrix[1][1]
  TN_2 = matrix[0][0] + matrix[0][2] + matrix[0][3] + matrix[0][4] + matrix[0][5] + matrix[2][0] + matrix[2][2] + matrix[2][3] + matrix[2][4] + matrix[2][5] + matrix[3][0] + matrix[3][2] + matrix[3][3] + matrix[3][4] + matrix[3][5] + matrix[4][0] + matrix[4][2] + matrix[4][3] + matrix[4][4] + matrix[4][5] + matrix[5][0] + matrix[5][2] + matrix[5][3] + matrix[5][4] + matrix[5][5]
  FP_2 = matrix[1][0] + matrix[1][2] + matrix[1][3] + matrix[1][4] + matrix[1][5]
  FN_2 = matrix[0][1] + matrix[2][1] + matrix[3][1] + matrix[4][1] + matrix[5][1]

  TP_3 = matrix[2][2]
  TN_3 = matrix[0][0] + matrix[0][1] + matrix[0][3] + matrix[0][4] + matrix[0][5] + matrix[1][0] + matrix[1][1] + matrix[1][3] + matrix[1][4] + matrix[1][5]  + matrix[3][0] + matrix[3][1] + matrix[3][3] + matrix[3][4] + matrix[3][5] + matrix[4][0] + matrix[4][1] + matrix[4][3] + matrix[4][4] + matrix[4][5] + matrix[5][0] + matrix[5][1] + matrix[5][3] + matrix[5][4] + matrix[5][5]
  FP_3 = matrix[2][0] + matrix[2][1] + matrix[2][3] + matrix[2][4] + matrix[2][5]
  FN_3 = matrix[0][2] + matrix[1][2] + matrix[3][2] + matrix[4][2] + matrix[5][2]

  TP_4 = matrix[3][3]
  TN_4 = matrix[0][0] + matrix[0][1] + matrix[0][2] + matrix[0][4] + matrix[0][5] + matrix[1][0] + matrix[1][1] + matrix[1][2] + matrix[1][4] + matrix[1][5] + matrix[2][0] + matrix[2][1] + matrix[2][2] + matrix[2][4] + matrix[2][5]  + matrix[4][0] + matrix[4][1] + matrix[4][2] + matrix[4][4] + matrix[4][5] + matrix[5][0] + matrix[5][1] + matrix[5][2] + matrix[5][4] + matrix[5][5]
  FP_4 = matrix[3][0] + matrix[3][1] + matrix[3][2] + matrix[3][4] + matrix[3][5]
  FN_4 = matrix[0][3] + matrix[1][3] + matrix[2][3] + matrix[4][3] + matrix[5][3]

  TP_5 = matrix[4][4]
  TN_5 = matrix[0][0] + matrix[0][1] + matrix[0][2] + matrix[0][3] + matrix[0][5] + matrix[1][0] + matrix[1][1] + matrix[1][2] + matrix[1][3] + matrix[1][5] + matrix[2][0] + matrix[2][1] + matrix[2][2] + matrix[2][3] + matrix[2][5] + matrix[3][0] + matrix[3][1] + matrix[3][2] + matrix[3][3] + matrix[3][5] + matrix[5][0] + matrix[5][1] + matrix[5][2] + matrix[5][3] + matrix[5][5]
  FP_5 = matrix[4][0] + matrix[4][1] + matrix[4][2] + matrix[4][3] + matrix[4][5]
  FN_5 = matrix[0][4] + matrix[1][4] + matrix[2][4] + matrix[3][4] + matrix[5][4]

  TP_6 = matrix[5][5]
  TN_6 = matrix[0][0] + matrix[0][1] + matrix[0][2] + matrix[0][3] + matrix[0][4] + matrix[1][0] + matrix[1][1] + matrix[1][2] + matrix[1][3] + matrix[1][4] + matrix[2][0] + matrix[2][1] + matrix[2][2] + matrix[2][3] + matrix[2][4] + matrix[3][0] + matrix[3][1] + matrix[3][2] + matrix[3][3] + matrix[3][4] + matrix[4][0] + matrix[4][1] + matrix[4][2] + matrix[4][3] + matrix[4][4]
  FP_6 = matrix[5][0] + matrix[5][1] + matrix[5][2] + matrix[5][3] + matrix[5][4]
  FN_6 = matrix[0][5] + matrix[1][5] + matrix[2][5] + matrix[3][5] + matrix[4][5]

  if (TP_1 + 0.5 * (FP_1 + FN_1)) != 0:
    F_score_1 = (TP_1) / (TP_1 + 0.5 * (FP_1 + FN_1))
    round(F_score_1, ndigits=4)
  else:
    F_score_1 = None

  if (TP_2 + 0.5 * (FP_2 + FN_2)) != 0:
    F_score_2 = (TP_2) / (TP_2 + 0.5 * (FP_2 + FN_2))
    round(F_score_2, ndigits=4)
  else:
    F_score_2 = None
  
  if (TP_3 + 0.5 * (FP_3 + FN_3)) != 0:
    F_score_3 = (TP_3) / (TP_3 + 0.5 * (FP_3 + FN_3))
    round(F_score_3, ndigits=4)
  else:
    F_score_3 = None
  
  if (TP_4 + 0.5 * (FP_4 + FN_4)) != 0:
    F_score_4 = (TP_4) / (TP_4 + 0.5 * (FP_4 + FN_4))
    round(F_score_4, ndigits=4)
  else:
    F_score_4 = None

  if (TP_5 + 0.5 * (FP_5 + FN_5)) != 0:
    F_score_5 = (TP_5) / (TP_5 + 0.5 * (FP_5 + FN_5))
    round(F_score_5, ndigits=4)
  else:
    F_score_5 = None

  if (TP_6 + 0.5 * (FP_6 + FN_6)) != 0:
    F_score_6 = (TP_6) / (TP_6 + 0.5 * (FP_6 + FN_6))
    round(F_score_6, ndigits=4)
  else:
    F_score_6 = None

  F_score = [F_score_1, F_score_2, F_score_3, 
             F_score_4, F_score_5, F_score_6]
  return F_score

#Steven Ohms
F_score_glass_unshuffled_1 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_2 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_3 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_4 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_5 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_6 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_7 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_8 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_unshuffled_9 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 2]])
F_score_glass_unshuffled_0 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 3]])

F_score_glass_shuffled_1 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_2 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 1, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_3 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_4 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 7, 0, 0, 1, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_5 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_6 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_7 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 1, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_8 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 3]])
F_score_glass_shuffled_9 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 2, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2]])
F_score_glass_shuffled_0 = F_score6x6([[7, 0, 0, 0, 0, 0], [0, 8, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 3]])

print(F_score_glass_unshuffled_1)
print(F_score_glass_unshuffled_2)
print(F_score_glass_unshuffled_3)
print(F_score_glass_unshuffled_4)
print(F_score_glass_unshuffled_5)
print(F_score_glass_unshuffled_6)
print(F_score_glass_unshuffled_7)
print(F_score_glass_unshuffled_8)
print(F_score_glass_unshuffled_9)
print(F_score_glass_unshuffled_0)
print("\n")
print(F_score_glass_shuffled_1)
print(F_score_glass_shuffled_2)
print(F_score_glass_shuffled_3)
print(F_score_glass_shuffled_4)
print(F_score_glass_shuffled_5)
print(F_score_glass_shuffled_6)
print(F_score_glass_shuffled_7)
print(F_score_glass_shuffled_8)
print(F_score_glass_shuffled_9)
print(F_score_glass_shuffled_0)

#Steven Ohms
iris_training_one = shuffle(train_merge(iris_ten, iris_two, iris_three, iris_four, iris_five, iris_six, iris_seven, iris_eight, iris_nine), iris_class)
iris_training_two = shuffle(train_merge(iris_ten, iris_one, iris_three, iris_four, iris_five, iris_six, iris_seven, iris_eight, iris_nine), iris_class)
iris_training_three = shuffle(train_merge(iris_ten, iris_one, iris_two, iris_four, iris_five, iris_six, iris_seven, iris_eight, iris_nine), iris_class)
iris_training_four = shuffle(train_merge(iris_ten, iris_one, iris_two, iris_three, iris_five, iris_six, iris_seven, iris_eight, iris_nine), iris_class)
iris_training_five = shuffle(train_merge(iris_ten, iris_one, iris_two, iris_three, iris_four, iris_six, iris_seven, iris_eight, iris_nine), iris_class)
iris_training_six = shuffle(train_merge(iris_ten, iris_one, iris_two, iris_three, iris_four, iris_five, iris_seven, iris_eight, iris_nine), iris_class)
iris_training_seven = shuffle(train_merge(iris_ten, iris_one, iris_two, iris_three, iris_four, iris_five, iris_six, iris_eight, iris_nine), iris_class)
iris_training_eight = shuffle(train_merge(iris_ten, iris_one, iris_two, iris_three, iris_four, iris_five, iris_six, iris_seven, iris_nine), iris_class)
iris_training_nine = shuffle(train_merge(iris_ten, iris_one, iris_two, iris_three, iris_four, iris_five, iris_six, iris_seven, iris_eight), iris_class)
iris_training_ten = shuffle(train_merge(iris_one, iris_two, iris_three, iris_four, iris_five, iris_six, iris_seven, iris_eight, iris_nine), iris_class)
 
print("iris first training start")
result_iris_one = Class(iris_one, iris_training_one, iris_class)
print("iris second training start")
result_iris_two = Class(iris_two, iris_training_two, iris_class)
print("iris third training start")
result_iris_three = Class(iris_three, iris_training_three, iris_class)
print("iris fourth training start")
result_iris_four = Class(iris_four, iris_training_four, iris_class)
print("iris fifth training start")
result_iris_five = Class(iris_five, iris_training_five, iris_class)
print("iris sixth training start")
result_iris_six = Class(iris_six, iris_training_six, iris_class)
print("iris seventh training start")
result_iris_seven = Class(iris_seven, iris_training_seven, iris_class)
print("iris eighth training start")
result_iris_eight = Class(iris_eight, iris_training_eight, iris_class)
print("iris ninth training start")
result_iris_nine = Class(iris_nine, iris_training_nine, iris_class)
print("iris tenth training start")
result_iris_ten = Class(iris_ten, iris_training_ten, iris_class)
 
print(zero_loss_func(result_iris_one))
print(zero_loss_func(result_iris_two))
print(zero_loss_func(result_iris_three))
print(zero_loss_func(result_iris_four))
print(zero_loss_func(result_iris_five))
print(zero_loss_func(result_iris_six))
print(zero_loss_func(result_iris_seven))
print(zero_loss_func(result_iris_eight))
print(zero_loss_func(result_iris_nine))
print(zero_loss_func(result_iris_ten))

print(confusion_matrix_iris(result_iris_one))
print(confusion_matrix_iris(result_iris_two))
print(confusion_matrix_iris(result_iris_three))
print(confusion_matrix_iris(result_iris_four))
print(confusion_matrix_iris(result_iris_five))
print(confusion_matrix_iris(result_iris_six))
print(confusion_matrix_iris(result_iris_seven))
print(confusion_matrix_iris(result_iris_eight))
print(confusion_matrix_iris(result_iris_nine))
print(confusion_matrix_iris(result_iris_ten))

#Gak Roppongi
soybean_training_one = shuffle(train_merge(soybean_ten, soybean_two, soybean_three, soybean_four, soybean_five, soybean_six, soybean_seven, soybean_eight, soybean_nine), soybean_class)
soybean_training_two = shuffle(train_merge(soybean_ten, soybean_one, soybean_three, soybean_four, soybean_five, soybean_six, soybean_seven, soybean_eight, soybean_nine), soybean_class)
soybean_training_three = shuffle(train_merge(soybean_ten, soybean_one, soybean_two, soybean_four, soybean_five, soybean_six, soybean_seven, soybean_eight, soybean_nine), soybean_class)
soybean_training_four = shuffle(train_merge(soybean_ten, soybean_one, soybean_two, soybean_three, soybean_five, soybean_six, soybean_seven, soybean_eight, soybean_nine), soybean_class)
soybean_training_five = shuffle(train_merge(soybean_ten, soybean_one, soybean_two, soybean_three, soybean_four, soybean_six, soybean_seven, soybean_eight, soybean_nine), soybean_class)
soybean_training_six = shuffle(train_merge(soybean_ten, soybean_one, soybean_two, soybean_three, soybean_four, soybean_five, soybean_seven, soybean_eight, soybean_nine), soybean_class)
soybean_training_seven = shuffle(train_merge(soybean_ten, soybean_one, soybean_two, soybean_three, soybean_four, soybean_five, soybean_six, soybean_eight, soybean_nine), soybean_class)
soybean_training_eight = shuffle(train_merge(soybean_ten, soybean_one, soybean_two, soybean_three, soybean_four, soybean_five, soybean_six, soybean_seven, soybean_nine), soybean_class)
soybean_training_nine = shuffle(train_merge(soybean_ten, soybean_one, soybean_two, soybean_three, soybean_four, soybean_five, soybean_six, soybean_seven, soybean_eight), soybean_class)
soybean_training_ten = shuffle(train_merge(soybean_one, soybean_two, soybean_three, soybean_four, soybean_five, soybean_six, soybean_seven, soybean_eight, soybean_nine), soybean_class)
 
print("soybean first training start")
result_soybean_one = Class(soybean_one, soybean_training_one, soybean_class)
print("soybean second training start")
result_soybean_two = Class(soybean_two, soybean_training_two, soybean_class)
print("soybean third training start")
result_soybean_three = Class(soybean_three, soybean_training_three, soybean_class)
print("soybean fourth training start")
result_soybean_four = Class(soybean_four, soybean_training_four, soybean_class)
print("soybean fifth training start")
result_soybean_five = Class(soybean_five, soybean_training_five, soybean_class)
print("soybean sixth training start")
result_soybean_six = Class(soybean_six, soybean_training_six, soybean_class)
print("soybean seventh training start")
result_soybean_seven = Class(soybean_seven, soybean_training_seven, soybean_class)
print("soybean eighth training start")
result_soybean_eight = Class(soybean_eight, soybean_training_eight, soybean_class)
print("soybean ninth training start")
result_soybean_nine = Class(soybean_nine, soybean_training_nine, soybean_class)
print("soybean tenth training start")
result_soybean_ten = Class(soybean_ten, soybean_training_ten, soybean_class)

print(confusion_matrix_soybean(result_soybean_one))
print(confusion_matrix_soybean(result_soybean_two))
print(confusion_matrix_soybean(result_soybean_three))
print(confusion_matrix_soybean(result_soybean_four))
print(confusion_matrix_soybean(result_soybean_five))
print(confusion_matrix_soybean(result_soybean_six))
print(confusion_matrix_soybean(result_soybean_seven))
print(confusion_matrix_soybean(result_soybean_eight))
print(confusion_matrix_soybean(result_soybean_nine))
print(confusion_matrix_soybean(result_soybean_ten))

print(zero_loss_func(result_soybean_one))
print(zero_loss_func(result_soybean_two))
print(zero_loss_func(result_soybean_three))
print(zero_loss_func(result_soybean_four))
print(zero_loss_func(result_soybean_five))
print(zero_loss_func(result_soybean_six))
print(zero_loss_func(result_soybean_seven))
print(zero_loss_func(result_soybean_eight))
print(zero_loss_func(result_soybean_nine))
print(zero_loss_func(result_soybean_ten))

#Steven Ohms
vote_training_one = shuffle(train_merge(vote_ten, vote_two, vote_three, vote_four, vote_five, vote_six, vote_seven, vote_eight, vote_nine), vote_class)
vote_training_two = shuffle(train_merge(vote_ten, vote_one, vote_three, vote_four, vote_five, vote_six, vote_seven, vote_eight, vote_nine), vote_class)
vote_training_three = shuffle(train_merge(vote_ten, vote_one, vote_two, vote_four, vote_five, vote_six, vote_seven, vote_eight, vote_nine), vote_class)
vote_training_four = shuffle(train_merge(vote_ten, vote_one, vote_two, vote_three, vote_five, vote_six, vote_seven, vote_eight, vote_nine), vote_class)
vote_training_five = shuffle(train_merge(vote_ten, vote_one, vote_two, vote_three, vote_four, vote_six, vote_seven, vote_eight, vote_nine), vote_class)
vote_training_six = shuffle(train_merge(vote_ten, vote_one, vote_two, vote_three, vote_four, vote_five, vote_seven, vote_eight, vote_nine), vote_class)
vote_training_seven = shuffle(train_merge(vote_ten, vote_one, vote_two, vote_three, vote_four, vote_five, vote_six, vote_eight, vote_nine), vote_class)
vote_training_eight = shuffle(train_merge(vote_ten, vote_one, vote_two, vote_three, vote_four, vote_five, vote_six, vote_seven, vote_nine), vote_class)
vote_training_nine = shuffle(train_merge(vote_ten, vote_one, vote_two, vote_three, vote_four, vote_five, vote_six, vote_seven, vote_eight), vote_class)
vote_training_ten = shuffle(train_merge(vote_one, vote_two, vote_three, vote_four, vote_five, vote_six, vote_seven, vote_eight, vote_nine), vote_class)
 
print("vote first training start")
result_vote_one = Class(vote_one, vote_training_one, vote_class)
print("vote second training start")
result_vote_two = Class(vote_two, vote_training_two, vote_class)
print("vote third training start")
result_vote_three = Class(vote_three, vote_training_three, vote_class)
print("vote fourth training start")
result_vote_four = Class(vote_four, vote_training_four, vote_class)
print("vote fifth training start")
result_vote_five = Class(vote_five, vote_training_five, vote_class)
print("vote sixth training start")
result_vote_six = Class(vote_six, vote_training_six, vote_class)
print("vote seventh training start")
result_vote_seven = Class(vote_seven, vote_training_seven, vote_class)
print("vote eighth training start")
result_vote_eight = Class(vote_eight, vote_training_eight, vote_class)
print("vote ninth training start")
result_vote_nine = Class(vote_nine, vote_training_nine, vote_class)
print("vote tenth training start")
result_vote_ten = Class(vote_ten, vote_training_ten, vote_class)
 
print(zero_loss_func(result_vote_one))
print(zero_loss_func(result_vote_two))
print(zero_loss_func(result_vote_three))
print(zero_loss_func(result_vote_four))
print(zero_loss_func(result_vote_five))
print(zero_loss_func(result_vote_six))
print(zero_loss_func(result_vote_seven))
print(zero_loss_func(result_vote_eight))
print(zero_loss_func(result_vote_nine))
print(zero_loss_func(result_vote_ten))

print(confusion_matrix_vote(result_vote_one))
print(confusion_matrix_vote(result_vote_two))
print(confusion_matrix_vote(result_vote_three))
print(confusion_matrix_vote(result_vote_four))
print(confusion_matrix_vote(result_vote_five))
print(confusion_matrix_vote(result_vote_six))
print(confusion_matrix_vote(result_vote_seven))
print(confusion_matrix_vote(result_vote_eight))
print(confusion_matrix_vote(result_vote_nine))
print(confusion_matrix_vote(result_vote_ten))

#Gak Roppongi
"""
F-score = (TP)/(TP+0.5(FP+FN))
"""
def F_score_2x2(matrix):
  TP_first = matrix[0][0]
  FP_first = matrix[0][1]
  FN_first = matrix[1][0]
  TN_first = matrix[1][1]

  TN_second = matrix[0][0]
  FN_second = matrix[0][1]
  FP_second = matrix[1][0]
  TP_second = matrix[1][1]

  F_score_first = (TP_first) / (TP_first + 0.5 * (FP_first + FN_first))
  F_score_second = (TP_second) / (TP_second + 0.5 * (FP_second + FN_second))

  F_score = [round(F_score_first, ndigits=4), round(F_score_second, ndigits=4)]
  return F_score

#Gak Roppongi
"""
F-score = (TP)/(TP+0.5(FP+FN))
"""
def F_score_3x3(matrix):
  TP_1 = matrix[0][0]
  TN_1 = matrix[1][1] + matrix[1][2] + matrix[2][1] + matrix[2][2] 
  FP_1 = matrix[0][1] + matrix[0][2]
  FN_1 = matrix[1][0] + matrix[2][0]

  TP_2 = matrix[1][1]
  TN_2 = matrix[0][0] + matrix[0][2] + matrix[2][0] + matrix[2][2]
  FP_2 = matrix[1][0] + matrix[1][2]
  FN_2 = matrix[0][1] + matrix[2][1]

  TP_3 = matrix[2][2]
  TN_3 = matrix[0][0] + matrix[0][1] + matrix[1][0] + matrix[1][1]
  FP_3 = matrix[2][0] + matrix[2][1]
  FN_3 = matrix[0][2] + matrix[1][2]

  F_score_1 = (TP_1) / (TP_1 + 0.5 * (FP_1 + FN_1))
  F_score_2 = (TP_2) / (TP_2 + 0.5 * (FP_2 + FN_2))
  F_score_3 = (TP_3) / (TP_3 + 0.5 * (FP_3 + FN_3))

  F_score = [round(F_score_1, ndigits=4), round(F_score_2, ndigits=4), round(F_score_3, ndigits=4)]
  return F_score

#Gak Roppongi
"""
F-score = (TP)/(TP+0.5(FP+FN))
"""
def F_score_4x4(matrix):
  TP_1 = matrix[0][0]
  TN_1 = matrix[1][1] + matrix[1][2] + matrix[1][3] + matrix[2][1] + matrix[2][2] + matrix[2][3] + matrix[3][1] + matrix[3][2] + matrix[3][3]
  FP_1 = matrix[0][1] + matrix[0][2] + matrix[0][3]
  FN_1 = matrix[1][0] + matrix[2][0] + matrix[3][0]

  TP_2 = matrix[1][1]
  TN_2 = matrix[0][0] + matrix[0][2] + matrix[0][3] + matrix[2][0] + matrix[2][2] + matrix[2][3] + matrix[3][0] + matrix[3][2] + matrix[3][3]
  FP_2 = matrix[1][0] + matrix[1][2] + matrix[1][3]
  FN_2 = matrix[0][1] + matrix[2][1] + matrix[3][1]

  TP_3 = matrix[2][2]
  TN_3 = matrix[0][0] + matrix[0][1] + matrix[0][3] + matrix[1][0] + matrix[1][1] + matrix[1][3] + matrix[3][0] + matrix[3][1] + matrix[3][2]
  FP_3 = matrix[2][0] + matrix[2][1] + matrix[2][3]
  FN_3 = matrix[0][2] + matrix[1][2] + matrix[3][2]

  TP_4 = matrix[3][3]
  TN_4 = matrix[0][0] + matrix[0][1] + matrix[0][2] + matrix[1][0] + matrix[1][1] + matrix[1][2] + matrix[2][0] + matrix[2][1] + matrix[2][2]
  FP_4 = matrix[3][0] + matrix[3][1] + matrix[3][2]
  FN_4 = matrix[0][3] + matrix[1][3] + matrix[2][3]

  F_score_1 = (TP_1) / (TP_1 + 0.5 * (FP_1 + FN_1))
  F_score_2 = (TP_2) / (TP_2 + 0.5 * (FP_2 + FN_2))
  F_score_3 = (TP_3) / (TP_3 + 0.5 * (FP_3 + FN_3))
  F_score_4 = (TP_4) / (TP_4 + 0.5 * (FP_4 + FN_4))

  F_score = [round(F_score_1, ndigits=4), round(F_score_2, ndigits=4), round(F_score_3, ndigits=4), round(F_score_4, ndigits=4)]
  return F_score

#Steven Ohms
F_score_breast_cancer_unshuffled_1 = F_score_2x2([[43, 0], [2, 24]])
F_score_breast_cancer_unshuffled_2 = F_score_2x2([[43, 0], [2, 24]])
F_score_breast_cancer_unshuffled_3 = F_score_2x2([[46, 0], [0, 24]])
F_score_breast_cancer_unshuffled_4 = F_score_2x2([[46, 0], [0, 24]])
F_score_breast_cancer_unshuffled_5 = F_score_2x2([[45, 1], [1, 23]])
F_score_breast_cancer_unshuffled_6 = F_score_2x2([[46, 0], [0, 24]])
F_score_breast_cancer_unshuffled_7 = F_score_2x2([[46, 0], [0, 24]])
F_score_breast_cancer_unshuffled_8 = F_score_2x2([[45, 0], [1, 24]])
F_score_breast_cancer_unshuffled_9 = F_score_2x2([[45, 0], [1, 24]])
F_score_breast_cancer_unshuffled_10 = F_score_2x2([[46, 0], [0, 25]])

F_score_breast_cancer_shuffled_1 = F_score_2x2([[43, 0], [2, 24]])
F_score_breast_cancer_shuffled_2 = F_score_2x2([[43, 0], [2, 24]])
F_score_breast_cancer_shuffled_3 = F_score_2x2([[45, 0], [1, 24]])
F_score_breast_cancer_shuffled_4 = F_score_2x2([[46, 0], [0, 24]])
F_score_breast_cancer_shuffled_5 = F_score_2x2([[45, 0], [1, 24]])
F_score_breast_cancer_shuffled_6 = F_score_2x2([[46, 0], [0, 24]])
F_score_breast_cancer_shuffled_7 = F_score_2x2([[46, 0], [0, 24]])
F_score_breast_cancer_shuffled_8 = F_score_2x2([[43, 0], [3, 24]])
F_score_breast_cancer_shuffled_9 = F_score_2x2([[44, 0], [2, 24]])
F_score_breast_cancer_shuffled_10 = F_score_2x2([[46, 0], [0, 25]])

#Gak Roppongi
F_score_vote_unshuffled_1 = F_score_2x2([[15, 0], [1, 26]])
F_score_vote_unshuffled_2 = F_score_2x2([[14, 2], [2, 24]])
F_score_vote_unshuffled_3 = F_score_2x2([[17, 0], [0, 26]])
F_score_vote_unshuffled_4 = F_score_2x2([[17, 0], [0, 27]])
F_score_vote_unshuffled_5 = F_score_2x2([[16, 0], [1, 27]])
F_score_vote_unshuffled_6 = F_score_2x2([[17, 1], [0, 26]])
F_score_vote_unshuffled_7 = F_score_2x2([[16, 0], [1, 27]])
F_score_vote_unshuffled_8 = F_score_2x2([[16, 0], [1, 27]])
F_score_vote_unshuffled_9 = F_score_2x2([[16, 3], [1, 24]])
F_score_vote_unshuffled_0 = F_score_2x2([[17, 1], [0, 26]])

F_score_vote_shuffled_1 = F_score_2x2([[15, 0], [1, 26]])
F_score_vote_shuffled_2 = F_score_2x2([[16, 4], [0, 22]])
F_score_vote_shuffled_3 = F_score_2x2([[17, 0], [0, 26]])
F_score_vote_shuffled_4 = F_score_2x2([[16, 0], [1, 27]])
F_score_vote_shuffled_5 = F_score_2x2([[16, 0], [1, 27]])
F_score_vote_shuffled_6 = F_score_2x2([[17, 1], [0, 26]])
F_score_vote_shuffled_7 = F_score_2x2([[16, 0], [1, 27]])
F_score_vote_shuffled_8 = F_score_2x2([[16, 0], [1, 27]])
F_score_vote_shuffled_9 = F_score_2x2([[16, 3], [1, 24]])
F_score_vote_shuffled_0 = F_score_2x2([[17, 1], [0, 26]])

#Steven Ohms
F_score_iris_unshuffled_1 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_2 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_3 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_4 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_5 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_6 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_7 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_8 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_9 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_unshuffled_0 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])

F_score_iris_shuffled_1 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_2 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_3 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_4 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_5 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_6 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_7 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_8 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_9 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])
F_score_iris_shuffled_0 = F_score_3x3([[5, 0, 0], [0, 5, 0], [0, 0, 5]])

#Gak Roppongi
F_score_soybean_unshuffled_1 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])
F_score_soybean_unshuffled_2 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])
F_score_soybean_unshuffled_3 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])
F_score_soybean_unshuffled_4 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 0], [0, 0, 1, 2]])
F_score_soybean_unshuffled_5 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]])
F_score_soybean_unshuffled_6 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]])
F_score_soybean_unshuffled_7 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]])
F_score_soybean_unshuffled_8 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]])
F_score_soybean_unshuffled_9 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]])
F_score_soybean_unshuffled_0 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]])

F_score_soybean_shuffled_1 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 1]])
F_score_soybean_shuffled_2 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 1]])
F_score_soybean_shuffled_3 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 1]])
F_score_soybean_shuffled_4 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 2]])
F_score_soybean_shuffled_5 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 2]])
F_score_soybean_shuffled_6 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 2]])
F_score_soybean_shuffled_7 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 2]])
F_score_soybean_shuffled_8 = F_score_4x4([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 0], [0, 0, 1, 2]])
F_score_soybean_shuffled_9 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 2]])
F_score_soybean_shuffled_0 = F_score_4x4([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 2]])

